# TCCC.ai Jetson MVP Configuration
# Optimized for minimal resource usage on edge devices

# System settings
system:
  log_level: DEBUG
  cache_dir: "data/cache"
  tmp_dir: "data/tmp"

# Audio settings for Jetson
audio_pipeline:
  sample_rate: 16000 # Revert back to 16000 Hz
  # Input/Output Configuration
  io:
    input_sources:
      # Default microphone input using PyAudio
      - name: "default_mic"
        type: "microphone" # Corrected type
        device_index: 0 # Set to default system audio device
        # Add other sounddevice options if needed (e.g., blocksize)
    default_input: "default_mic"
  channels: 1
  bit_depth: 16
  chunk_size: 2048
  vad_enabled: true
  vad_threshold: 0.5
  vad_min_speech_duration_ms: 250
  battlefield_noise_filter: true
  enhanced_voice_isolation: true

# STT engine settings
stt_engine:
  model: "tiny.en"
  model_path: "models/stt"
  compute_type: "float16"
  device: "cuda"
  beam_size: 1
  language: "en"

# LLM settings
llm_analysis:
  model:
    primary:
      provider: "local-gguf"
      name: "phi-2"
      path: "models/phi-2-gguf"
      file: "phi-2.Q4_K_M.gguf"
  hardware: # Hardware/runtime settings for the LLM
    enable_acceleration: true # Added for get_status()
    cuda_device: 0            # Added for get_status()
    quantization: "gguf"      # Added for get_status()
    max_tokens: 256      # Max tokens for generation
    temperature: 0.3     # Sampling temperature
    device: "cuda"       # Use GPU acceleration ('cuda' or 'cpu')

# Power and resource management
power_management:
  mode: "balanced"
  max_memory_usage_gb: 6.0
  cpu_threads: 2
  enable_monitoring: true
  monitoring_interval_seconds: 10
